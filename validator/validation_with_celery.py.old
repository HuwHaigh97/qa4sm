import matplotlib as mpl
# import warnings
from validator.mailer import send_val_done_notification
from celery.app import shared_task
mpl.use('Agg') ## this allows headless graph production
import matplotlib.pyplot as plt

from datetime import datetime
from dateutil.tz import tzlocal
import logging
from os import makedirs, errno, listdir, path
from re import sub as regex_sub
from zipfile import ZipFile

import pygeogrids.netcdf # bugfix
from pygeobase.io_base import GriddedBase
from ismn.interface import ISMN_Interface
from c3s_quality.readers_writers.c3s import c3s_v201706_daily_tcdr_combined_ts_nc as c3s_read  # # TODO: use new C3S reader package instead
from gldas.interface import GLDASTs
from smap_io.interface import SMAPTs

import netCDF4
from netCDF4 import Dataset
from pytesmo.validation_framework.results_manager import netcdf_results_manager
from pytesmo.validation_framework.validation import Validation
# from pytesmo.validation_framework.adapters import SelfMaskingAdapter

import numpy as np
import pandas as pd
from validator.metrics import EssentialMetrics
from validator.hacks import TimezoneAdapter
from validator.models import ValidationRun

from valentina.settings import DATA_FOLDER
from valentina.settings import MEDIA_ROOT

#from .tasks import *
# from celery import group

# logging.captureWarnings(True)

__logger = logging.getLogger(__name__)

OUTPUT_FOLDER = MEDIA_ROOT

METRICS = {'R' : 'Pearson\'s r',
           'p_R' : 'Pearson\'s r p-value',
           'rho' : 'Spearman\'s rho',
           'p_rho' : 'Spearman\'s rho p-value',
           'RMSD' : 'Root-mean-square deviation',
           'BIAS' : 'Bias (difference of means)',
           'n_obs' : '# observations',
           'urmsd' : 'Unbiased root-mean-square deviation',
           'RSS' : 'Residual sum of squares',
           }

def create_reader(dataset_name, dataset_version):
    if dataset_name == ValidationRun.ISMN:
        ismn_data_folder = path.join(DATA_FOLDER, 'ISMN.mini')  ## default
        if dataset_version == ValidationRun.ISMN_V20180712_TEST:
            ismn_data_folder = path.join(DATA_FOLDER, 'ISMN.selection') ## TODO: figure out how to store this path configuration - config file, db, ???
        if dataset_version == ValidationRun.ISMN_V20180712_USA:
            ismn_data_folder = path.join(DATA_FOLDER, 'ISMN.USA')
        if dataset_version == ValidationRun.ISMN_V20180830_GLOBAL:
            ismn_data_folder = path.join(DATA_FOLDER, 'ISMN.global')

        ismn_reader = ISMN_Interface(ismn_data_folder)
        return ismn_reader

    if dataset_name == ValidationRun.C3S:
        c3s_data_folder = path.join(DATA_FOLDER, 'C3S/{}/TCDR/063_images_to_ts/combined-daily'.format(dataset_version))
        c3s_reader = c3s_read(c3s_data_folder)
        return c3s_reader

    if dataset_name == ValidationRun.GLDAS:
        gldas_data_folder = path.join(DATA_FOLDER, 'GLDAS/{}'.format(dataset_version))
        gldas_reader = GLDASTs(gldas_data_folder)
        return gldas_reader

    if dataset_name == ValidationRun.SMAP:
        smap_data_folder = path.join(DATA_FOLDER, 'SMAP_v5/AM_descending/netcdf')
        smap_reader = SMAPTs(smap_data_folder)
        return smap_reader

    raise ValueError("Reader for dataset '{}' not available".format(dataset_name))

def create_masking_reader(reader):
    if isinstance(reader, ISMN_Interface):
        ismn_masking_reader = TimezoneAdapter(reader, '==', 'G', 'soil moisture_flag')
        return ismn_masking_reader
    if isinstance(reader, c3s_read):
        c3s_masking_reader = TimezoneAdapter(reader, '==', 0, 'flag')
        return c3s_masking_reader
    if isinstance(reader, SMAPTs):
        smap_masking_reader = TimezoneAdapter(reader, '>', 0, 'soil_moisture')
        return smap_masking_reader
    if isinstance(reader, GLDASTs):
        gldas_masking_reader3 = TimezoneAdapter(reader, '<', 0.001, 'SWE_inst')
        gldas_masking_reader2 = TimezoneAdapter(gldas_masking_reader3, '>', 0.0, 'SoilMoi0_10cm_inst')
        gldas_masking_reader1 = TimezoneAdapter(gldas_masking_reader2, '>', 1., 'SoilTMP0_10cm_inst')
        return gldas_masking_reader1

    raise ValueError("Masking for reader '{}' not available".format(reader))

def create_jobs(validation_run):
    jobs = []

    ref_reader = create_reader(validation_run.ref_dataset, validation_run.ref_version)

    if isinstance(ref_reader, ISMN_Interface):
#         data_reader = create_reader(validation_run.data_dataset, validation_run.data_version)

        ids = ref_reader.get_dataset_ids(variable=validation_run.ref_variable, min_depth=0, max_depth=0.1)
        for idx in ids:
            metadata = ref_reader.metadata[idx]
            jobs.append((idx, metadata['longitude'], metadata['latitude']))

    elif isinstance(ref_reader, GriddedBase):
        gpis, lons, lats, cells = ref_reader.grid.get_grid_points()

        grid_table = pd.DataFrame(data={'gpis': gpis, 'lons': lons, 'lats': lats, 'cells':cells})
        grid_table.sort_values(by=['cells'], inplace=True)
        jobs = tuple(zip(grid_table['gpis'].values, grid_table['lons'].values, grid_table['lats'].values))
    else:
        raise ValueError("Can't generate jobs from reference reader {}".format(ref_reader))

    return jobs

def mkdir_if_not_exists(the_dir):
    try:
        makedirs(the_dir)
    except OSError as e:
        if e.errno != errno.EEXIST:
            raise

def first_file_in(the_dir, extension):
    for file in listdir(the_dir):
        if file.endswith(extension):
            return path.join(the_dir, file)
    return None

def set_outfile(validation_run, run_dir):
    outfile = first_file_in(run_dir, '.nc')
    if outfile is not None:
        outfile = regex_sub('/?' + OUTPUT_FOLDER + '/?', '', outfile)
        validation_run.output_file.name = outfile

def generate_graph(validation_run, outfolder, variable, label):
    if not validation_run.output_file:
        return None

    filename = path.join(outfolder, 'boxplot_{}.png'.format(variable))

    with netCDF4.Dataset(validation_run.output_file.path) as ds:
        values = ds.variables[variable][:]

    values = [x for x in values if (np.isnan(x) != True)]

    plt.boxplot(values)
    plt.ylabel(label)
    plt.title('Validation {} ({}) vs {} ({})'.format(
        validation_run.data_dataset,
        validation_run.data_version,
        validation_run.ref_dataset,
        validation_run.ref_version))
    ax = plt.gca()
    ax.get_xaxis().set_visible(False)

    plt.savefig(filename)

    return filename

def generate_all_graphs(validation_run, outfolder):
    zipfilename = path.join(outfolder, 'graphs.zip')
    __logger.debug('Trying to create zipfile {}'.format(zipfilename))
    with ZipFile(zipfilename, 'w') as myzip:
        for metric in METRICS:
            fn = generate_graph(validation_run, outfolder, metric, METRICS[metric])
            arcname = path.basename(fn)
            myzip.write(fn, arcname=arcname)

def save_validation_config(validation_run):
    try:
        ds = Dataset(path.join(OUTPUT_FOLDER, validation_run.output_file.name), "a", format="NETCDF4")
        if(validation_run.interval_from is None):
            ds.val_interval_from="N/A"
        else:
            ds.val_interval_from=validation_run.interval_from.strftime('%m/%d/%Y %H:%M')

        if(validation_run.interval_to is None):
            ds.val_interval_to="N/A"
        else:
            ds.val_interval_to=validation_run.interval_to.strftime('%m/%d/%Y %H:%M')

        ds.val_data_dataset=validation_run.data_dataset
        ds.val_data_version=validation_run.data_version
        ds.val_data_variable=validation_run.data_variable
        ds.val_ref_dataset=validation_run.ref_dataset
        ds.val_ref_version=validation_run.ref_version
        ds.val_ref_variable=validation_run.ref_variable
        ds.val_scaling_ref=validation_run.scaling_ref
        ds.val_scaling_method=validation_run.scaling_method
        ds.close()
    except Exception as e:
        __logger.error("Validation configuration could not be stored. {}".format(e))

def create_pytesmo_validation(validation_run):
    data_reader = create_reader(validation_run.data_dataset, validation_run.data_version)
    ref_reader = create_reader(validation_run.ref_dataset, validation_run.ref_version)

    data_reader = create_masking_reader(data_reader)
    ref_reader = create_masking_reader(ref_reader)

    ds_name = validation_run.data_dataset
    if ds_name == validation_run.ref_dataset:
        ds_name += '2'

    datasets = {
            validation_run.ref_dataset: {
                'class': ref_reader,
                'columns': [validation_run.ref_variable]
                },
            ds_name: {
                'class': data_reader,
                'columns': [validation_run.data_variable]
                }}

    period = None
    if validation_run.interval_from is not None and validation_run.interval_to is not None:
        period = [validation_run.interval_from, validation_run.interval_to]

    metrics = EssentialMetrics()

    if validation_run.scaling_ref == ValidationRun.SCALE_REF:
        scaling_ref=ds_name ## if you scale the reference dataset, the scaling reference is the normal dataset %-P
    else:
        scaling_ref=validation_run.ref_dataset


    val = Validation(
            datasets,
            spatial_ref=validation_run.ref_dataset,
            temporal_ref=ds_name,
            temporal_window=0.5,
            scaling=validation_run.scaling_method,
            scaling_ref=scaling_ref,
            metrics_calculators={(2, 2): metrics.calc_metrics},
            period=period)

    return val

@shared_task
def execute_job(validation_run, job):
    val = create_pytesmo_validation(validation_run)
    result = val.calc(*job)
    return {'result':result,'job':job}

def check_and_store_results(validation_run,job, results,save_path):
        print(job)

        if len(results) < 1:
            validation_run.error_points += 1
            __logger.warn('Problematic job: {} - no results'.format(job))
            return

        if np.isnan(next(iter(results.values()))['R'][0]):
            __logger.warn('Potentially problematic job: {} - R is nan'.format(job))

        netcdf_results_manager(results, save_path)
        validation_run.ok_points+=1

def run_validation(validation_run):

    try:
        __logger.info("Starting validation: {}".format(validation_run))


        run_dir = path.join(OUTPUT_FOLDER, str(validation_run.id))
        mkdir_if_not_exists(run_dir)

        jobs = create_jobs(validation_run)

        __logger.debug("Jobs to run: {}".format(jobs))

        save_path = run_dir

        validation_run.total_points = len(jobs)


        #async_job = group([execute_job.s(validation_run,job) for job in jobs])
        async_results = []
        for job in jobs:
            async_results.append(execute_job.delay(validation_run,job))


        for async_result in async_results:

            try:
                result_dict=async_result.get(240)
                results = result_dict['result']
                job = result_dict['job']

                check_and_store_results(validation_run, job, results, save_path)
            except Exception:
                validation_run.error_points += 1
                __logger.exception('Celery could not execute the job. Job ID: {} Error: {}'.format(async_result.id,async_result.info))



        set_outfile(validation_run, run_dir)
        validation_run.save() # let's save before we do anything else...

        save_validation_config(validation_run)
        generate_all_graphs(validation_run, run_dir)

    except Exception:
        __logger.exception('Unexpected exception during validation {}:'.format(validation_run))

    finally:
        validation_run.end_time = datetime.now(tzlocal())
        __logger.info("Validation finished: {}. Jobs: {}, Errors: {}, OK: {}".format(
            validation_run, validation_run.total_points, validation_run.error_points, validation_run.ok_points))
        if (validation_run.error_points + validation_run.ok_points) != validation_run.total_points:
            __logger.warn("Caution, # of jobs, # of errors, and # of OK points don't match!")
        validation_run.save()

        send_val_done_notification(validation_run)

    return validation_run
